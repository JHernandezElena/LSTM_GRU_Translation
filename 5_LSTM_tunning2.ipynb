{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxRczK0-onna"
   },
   "source": [
    "### MODEL TUNNING\n",
    "- ### INCREASED FINAL DROPUT LAYER TO 0,2 TO AVOID OVERFITTING\n",
    "- ### REDUCED BATCH TO 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFjMXM_lrFT_"
   },
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfuvQhqHrFUE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TkDJx86rFUk"
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maMFMj13rFUl"
   },
   "source": [
    "Our data is a text file of English-Spanish sentence pairs. First we will read the file using the function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQBlct8mrFUn"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoDOIggQrFUt"
   },
   "source": [
    "Now let's define a function to split the text into English-Spanish pairs separated by '\\n' and then split these pairs into English sentences and Spanish sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Za-jDoarFUw"
   },
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAkxvYtxrFU6"
   },
   "source": [
    "__Download the data from [here.](http://www.manythings.org/anki/deu-eng.zip)__ and extract \"spa.txt\" in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1118,
     "status": "ok",
     "timestamp": 1587994178437,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "jaqdeOYksW6E",
    "outputId": "85707fe9-d9e0-464d-b50b-a5ecaec6f348"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Navigate to code directory\n",
    "%cd /content/drive/My Drive/NLP_Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7giidivarFU8"
   },
   "outputs": [],
   "source": [
    "data = read_text(\"spa-eng/spa.txt\")\n",
    "spa_eng = to_lines(data)\n",
    "spa_eng = array(spa_eng)[:,0:2] #NOS QUEDAMOS SOLO CON LAS PRIMERAS COLUMNAS QUE TIENEN LA INFORMACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G1hy6LL4rFVE"
   },
   "source": [
    "The actual data contains over 150,000 sentence-pairs. However, we will use the first 80,000 sentence pairs only to reduce the training time of the model. You can change this number as per you system computation power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLlbn_7CrFVY"
   },
   "outputs": [],
   "source": [
    "#PARA ENTRENAR EL PRIMER MODELO VOY A USARLAS TODAS ASI QUE COMENTO ESTA LINEA\n",
    "spa_eng = spa_eng[:80000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgGSEJ-yrFVd"
   },
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYjg2CJ5rFVe"
   },
   "source": [
    "#### Text Cleaning\n",
    "\n",
    "Let's take a look at our data, then we will decide which pre-processing steps to adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2464,
     "status": "ok",
     "timestamp": 1587994179818,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "QprSH6tXrFVf",
    "outputId": "6f606f48-34f7-46c3-c49d-83ff980401ed",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Ve.'],\n",
       "       ['Go.', 'Vete.'],\n",
       "       ['Go.', 'Vaya.'],\n",
       "       ...,\n",
       "       ['Suddenly, all the lights went out.',\n",
       "        'De repente se apagaron todas las luces.'],\n",
       "       ['Suddenly, the dog started barking.',\n",
       "        'De repente el perro empezó a ladrar.'],\n",
       "       ['Swimming in the pond is dangerous.',\n",
       "        'Es peligroso nadar en la laguna.']], dtype='<U332')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tw-3xuucrFVj"
   },
   "source": [
    "We will get rid of the punctuation marks, and then convert the text to lower case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ni6bXQzi0Qnd"
   },
   "source": [
    "#### *IMPORTANTE QUITAR LA EXCLAMACION HACIA ARRIBA PARA EL ESPAÑOL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_G43XlGzrFVl"
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "spa_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in spa_eng[:,0]]\n",
    "spa_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in spa_eng[:,1]]\n",
    "\n",
    "## TAMBIEN QUITAMOS ESTA EXCLAMACION QUE LO ANTERIOR NO LO QUITA\n",
    "spa_eng[:,0] = [s.translate(str.maketrans('', '', '¡')) for s in spa_eng[:,0]]\n",
    "spa_eng[:,1] = [s.translate(str.maketrans('', '', '¡')) for s in spa_eng[:,1]]\n",
    "\n",
    "# convert to lowercase\n",
    "for i in range(len(spa_eng)):\n",
    "    spa_eng[i,0] = spa_eng[i,0].lower()\n",
    "    \n",
    "    spa_eng[i,1] = spa_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4364,
     "status": "ok",
     "timestamp": 1587994181740,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "RNFKNfJDrFWB",
    "outputId": "6149991e-9dba-470d-a842-898d03dc496f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 've'],\n",
       "       ['go', 'vete'],\n",
       "       ['go', 'vaya'],\n",
       "       ...,\n",
       "       ['suddenly all the lights went out',\n",
       "        'de repente se apagaron todas las luces'],\n",
       "       ['suddenly the dog started barking',\n",
       "        'de repente el perro empezó a ladrar'],\n",
       "       ['swimming in the pond is dangerous',\n",
       "        'es peligroso nadar en la laguna']], dtype='<U332')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0wbcBMDrFWL"
   },
   "source": [
    "#### Text to Sequence Conversion\n",
    "\n",
    "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and Spanish, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8j330RxorFWV"
   },
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "spa_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in spa_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in spa_eng[:,1]:\n",
    "    spa_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4316,
     "status": "ok",
     "timestamp": 1587994181742,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "B-_oTwiyrFWd",
    "outputId": "5d96861f-3aba-41ab-f00d-c9ad300f9d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'spa':spa_l})\n",
    "#print(length_df)\n",
    "print(max(length_df.eng))\n",
    "print(max(length_df.spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4756,
     "status": "ok",
     "timestamp": 1587994182198,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "yf2z3GdorFWj",
    "outputId": "faa9ecb4-8efc-49ee-f2dc-bbb5f1a09f2a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAd5ElEQVR4nO3df7BcZZ3n8fdnwo9hgJkkAjH8GC/uRmqBjBEisMuMG4clBJg1YqkTdsYkwC4yRWqgKltlcKyBBamKM4Alsy4uaJYwqyQoolkSJmYoUzNuGSAgEEJk8oMogZgoQUjERRO/+8d5Opz0PX1vd9++fU73/byqum7f5zznnKc75+Z7fjzP91FEYGZmY9tvld0AMzMrn4OBmZk5GJiZmYOBmZnhYGBmZjgYmJkZDgZmZoaDgZmZ4WBgZmY4GPQkSSdKelDSTyW9KOkvU/lNkh6QdJ+kvZI2SpqeW+8sST9Iy74uabmkz5b3ScyaJ+lTkl5Ox+8Lki5Ix/w30rG8V9JTkt6bW2eRpK1p2fOSLivzM1SZg0GPkfRbwP8BngFOAi4Arpd0UaryIWAZMB5YAfz3tN4RwEPAvcBE4H7AfxjWEySdBiwA3h8RxwIXAdvT4tnA18mO668B35J0eFq2Ffgj4PeA/wb8b0mTu9j0nuFg0HveDxwfETdHxK8iYhtwDzAnLf9eRKyKiAPA3wO1s6TzgMOAOyPi1xHxTeDxbjferE0HgCOB0yUdHhHbI2JrWvZkRHwjIn4N3AH8NtnxTkR8PSJeiYjfRMRyYDNwThkfoOocDHrPu4ATJf289gI+DUxKy3+Sq/sm8NuSDgNOBF6OQzMTvtSVFpuNUERsAa4HbgJ2S1om6cS0+KVcvd8AO8iOdyTNlfR07m/lTOC4rja+RzgY9J6XgBcjYnzudWxEXDLMejuBkyQpV3bK6DXTrLMi4msR8YdkJ0QBfC4tOngcp9uoJwOvSHoX2VXzAuAdETEeeA4QNoiDQe95HHgjPUw7StI4SWdKev8w632f7FJ7gaTDJM3Gl8vWIySdJumPJR0J/D/gl2THM8DZkj6SroCvB94C1gFHkwWNn6ZtXEF2ZWAFHAx6THoW8B+BacCLwM+AL5M9IBtqvV8BHwGuAn4O/DnwMNkfjlnVHQksJjvefwKcQHZ7FODbwJ8CrwGfAD6Snos9D9xOdiK0C5gK/N8ut7tnyJPbjF2SHgO+FBH/q+y2mLVD0k3Av46IPy+7Lb3OVwZjiKR/L+md6TbRPOAPgH8ou11mVr7Dym6AddVpwAPAMWT9rz8aETvLbZKZVYFvE5nVkXQKcB/wTuA3wN0R8QVJE4HlwADZgKePR8RrqYfWF4BLyLrzzo+Ip9K25gGfSZv+bEQsTeVnkw0APApYBVwX/mO0Evk2kdlg+4GFEfFvyAYvXSvpdGAR8GhETAEeTb8DXAxMSa+rgbsAUvC4ETiXrOfWjZImpHXuSnVr683qwucya6hnbxMdd9xxMTAw0LX9/eIXv+Doo4/u2v6a4TY1p1GbnnzyyZ9FxPH15enW2c70fq+kTWSpP2YDM1K1pcBa4FOp/L50Zr9O0viU8mAGsCYi9gBIWgPMkrQW+N2I+H4qvw/4MPDIUJ+j28f8SFXxWGhFL7d/qLY3Ou57NhgMDAywfv36ru1v7dq1zJgxo2v7a4bb1JxGbZL0o+HWlTQAvA94DJhUe8YSETslnZCqncSho7l3pLKhyncUlBft/2qyKwgmTZrEbbfdNlyTK2Pfvn0cc8wxZTejbb3c/qHa/sEPfrDwuO/ZYGA22iQdAzwIXB8Rbxw6ePvQqgVl0Ub54MKIu4G7AaZPnx5VC7RDqeKJQSt6uf3ttN3PDMwKpKyXDwJfTUn9AHbVMl6mn7tT+Q4OTe1xMvDKMOUnF5SblcbBwKxO6h30FWBTRNyRW7QCmJfezyMb+Vorn6vMecDr6XbSamCmpAnpwfFMYHVatlfSeWlfc3PbMiuFbxOZDXY+WVqDDZKeTmWfJkuH8ICkq4AfAx9Ly1aRdSvdQta19AqAiNgj6RbgiVTv5trDZOAveLtr6SMM8/DYbLQ5GJjViYjv0Tiz5QUF9QO4tsG2lgBLCsrX46RpViG+TWRmZg4GZmbmYGBmZjgYmJkZfoDcswYWrWTh1P3MX7QSgO2LLy25RTYWDKTjLc/HXn/wlYGZmTkYmJmZg4GZmeFgYGZmOBiYmRlNBANJp0j6rqRNkjZKui6VT5S0RtLm9HNCKpekOyVtkfSspLNy25qX6m9O0wHWys+WtCGtc6eGyBVsZtU2sGglA4tWsuHl1wt7H1k1NXNl4CkAzcz63LDBICJ21ib3joi9QH4KwKWp2lKyafsgNwVgRKwDalMAXkSaAjAiXgNqUwBOJk0BmBJ+3ZfblpmZdUFLg86qNgXg2rVrW2n+iOzbt6+r+xvOwqn7mXRU9hOoTNuq9j1BNdtkVjVNB4OxPgVg1abAm59GIN++Ifsn3P5nM8ptUFK17wmq2SazqmmqN5GnADQz62/N9CbyFIBmZn2umdtEngLQzKzPDRsMPAWgjUWSlgB/AuyOiDNT2XLgtFRlPPDziJiWOlZsAl5Iy9ZFxDVpnbN5+0RnFXBdRETqar0cGAC2Ax9PvezMSuERyGbF7qVuvEtE/GlETIuIaWTP0L6ZW7y1tqwWCJJGY2gajdMxK4WDgVmBiPgnYE/RsvRs6+PA/UNtY5gxNI3G6ZiVwpPbmLXuj4BdEbE5V3aqpB8AbwCfiYh/ZugxNI3G6RyizLE1RWrjWvLq21SrUxsHU3ab29XL41PaabuDgVnrLufQq4KdwO9HxKvpGcG3JJ1BC2NoGilzbE2R+UUzndWNcanVqY2DqcoYmFb18viUdtruYGDWAkmHAR8Bzq6VRcRbwFvp/ZOStgLvYegxNLskTU5XBflxOmal8DMDs9b8B+CHEXHw9o+k4yWNS+/fTfageNswY2gajdMxK4WDgVkBSfcD3wdOk7QjjacBmMPgB8cfAJ6V9AzwDeCaujE0XyYbd7OVt8fQLAYulLQZuDD9blYa3yYyKxARlzcon19Q9iBZV9Oi+oVjaCLiVQrG6ZiVxVcGZmbmYGBmZg4GZmaGg4GZmeEHyJVQP2n49sWXltQSMxurfGVgZmYOBmZm5mBgZmY0N+3lEkm7JT2XK1su6en02l6bAU3SgKRf5pZ9KbfO2ZI2SNoi6c40PB9JEyWtkbQ5/ZwwGh/UzMwaa+bK4F48yYeZWV8bNhh4kg8zs/430q6lXZvkA8qd6GM0J7qonzCkmf0snLr/4OQhza7TDVWcEKSKbTKrmpEGg65N8gHlTvQxmhNd1E8Y0sxkIPMXrTw4eUiz63RDFScEqWKbzKqm7WDgST7MzPrHSK4MCif5APZExIG6ST72SNor6TzgMbJJPv4urVab5GMxnuRjVHmks5k10kzXUk/yYWbW54a9MvAkH2Zm/c8jkM3MzMHArEiDkfc3SXo5N8L+ktyyG9Lo+hckXZQrn5XKtkhalCs/VdJjaeT9cklHdO/TmQ3mYGBW7F7qRt4nn8+NsF8FIOl0smdoZ6R1/oekcZLGAV8ELgZOBy5PdQE+l7Y1BXgNuKp+R2bd5GBgVmCokfcFZgPLIuKtiHiRrJPEOem1JSK2RcSvgGXA7DRy/4/JOlmAR95bBXhyG7PWLJA0F1gPLIyI18hG06/L1cmPsH+prvxc4B3AzyNif0H9Q5Q56r5I/Wh5GDz6vVanNkK+7Da3q5dHrrfTdgcDs+bdBdxCNnr+FuB24Eoaj7AvuvKOIeoPLixx1H2R+tHyMHj0e61ObYR8VUbHt6qXR66303YHA7MmRcSu2ntJ9wAPp193AKfkquZH2BeV/wwYL+mwdHWQr29WCj8zMGtSSpdScxlQ62m0Apgj6UhJp5KNvH8ceAKYknoOHUH2kHlFytz7XeCjaX2PvLfS+crArEAaeT8DOE7SDuBGYIakaWS3dLYDnwSIiI2SHgCeB/YD10bEgbSdBcBqYBywJCI2pl18Clgm6bPAD4CvdOmjmRVyMDAr0GDkfcP/sCPiVuDWgvJVwKqC8m1kvY3MKsG3iczMzMHAzMwcDMzMDAcDMzPDwcDMzHAwMDMzmpvpzKl8zcz6XDNXBvfiVL5mZn1t2GDgVL5mZv1vJCOQu5rKF8pN5zua6Wzr0wI3s5+FU/cfTBHcyjqt7qdVVUz7W8U2mVVNu8Gg66l8odx0vqOZzrY+LXAzKX/nL1p5MEVwK+u0up9WVTHtbxXbZFY1bQUDp/I1M+svbXUtdSpfM7P+MuyVgVP5mlmnDdTfslx8aUktsZphg4FT+ZqZ9T+PQDYzMwcDMzPzTGdmltTfxwffyx9LfGVgVqBBTq6/lfRDSc9KekjS+FQ+IOmXuVxdX8qtc7akDSkn151p1D2SJkpak3JyrZE0ofuf0uxtDgZmxe5lcE6uNcCZEfEHwL8AN+SWbc3l6romV34X2aj5KelV2+Yi4NGUk+vR9LtZaRwMzAoU5eSKiO/kUqesIxsk2VAaj/O7EfH9NKbmPt7OvTWbLBcXOCeXVYCfGZi150pgee73UyX9AHgD+ExE/DNZnq0duTr53FuTImInQETslHRC0U66mY+rPncVDM5f1UqdWu6sojZ3I0/WSPVyTqt22u5gYNYiSX9FNqjyq6loJ/D7EfGqpLOBb0k6gxZzbxXpZj6u+txVMDh/VSt1armzinJgdSNP1kj1ck6rdtruYGDWAknzgD8BLki3foiIt4C30vsnJW0F3kN2JZC/lZTPvbVL0uR0VTAZ2N2tz2BWxM8MzJokaRZZ+pQPRcSbufLj0wROSHo32YPibek20F5J56VeRHN5O/fWCrJcXOCcXFYBvjIwK9AgJ9cNwJHAmtRDdF3qOfQB4GZJ+4EDwDURUXv4/BdkPZOOAh5JL4DFwAOSrgJ+DHysCx/LrCEHA7MCreTkiogHgQcbLFsPnFlQ/ipwwUjaaNZJvk1kZmYOBmZm5mBgZmY0EQyco8XMrP81c2VwL87RYmbW14YNBs7RYmbW/zrRtbQrOVqgu3la6o1mnpJ28rQsnLr/YO6XVtZpdT+tqmI+lyq2yaxqRhQMupmjBbqbp6XeaOYpaSdPy/xFKw/mfmllnVb306oq5nOpYpvMqqbtYOAcLWZm/aOtrqXO0WJm1l+GvTJwjhYzs/43bDBwjhYzs/7nEchmZuZgYGZmDgZmZoaDgZmZ4WBgZmY4GJiZGQ4GZoUapG4vTLeuzJ0pPfuzks7KrTMv1d+cRu3XygtTupuVxcHArNi9DE7d3ijd+sW8nZr9arJ07UiaSDZI81zgHODG3HwdjVK6m5XCwcCsQFHqdhqnW58N3BeZdcD4lGfrImBNROyJiNfI5gGZNUxKd7NSdCKFtdlY0Sjd+knAS7l6tRTtQ5U3Sul+iG6mba9PcQ6D05y3UqeWYr2ozd1Ipz5SvZz6vJ22OxiYjVyjFO2tlg8u7GLa9voU5zA4zXkrdWop1otSpXcjnfpI9XLq83ba7ttEZs3blW7x1Gbvq6Vb3wGckqtXS9E+VHmjlO5mpXAwMGteo3TrK4C5qVfRecDr6XbSamCmpAnpwfFMYPUwKd3NSuHbRGYFGqRub5RufRVwCbAFeBO4AiAi9ki6BXgi1bu5iZTuZqVwMDAr0CB1OxSkW089gq5tsJ0lwJKC8sKU7mZl8W0iMzNrLhh4NKaZWX9r9srgXjwa08ysbzUVDDwa08ysv43kAXJfj8asN5qjEdsZjblw6v6DIzxbWafV/bSqiqM2q9gms6oZjd5EfTEas17RiL6B+lGUiy9ta9vtjMacv2jlwRGerazT6n5aVcVRm1Vsk1nVjKQ3kUdjmpn1iZEEA4/GNDPrE03dJvJoTDOz/tZUMPBoTDOz/uYRyGZm5mBgZmYOBmZmhoOBmZnhYGBmZjgYmJkZDgZmZoaDgZmZ4WkvrQ2dStDXiySdBizPFb0b+GtgPPBfgJ+m8k9HxKq0zg3AVcAB4C8jYnUqnwV8ARgHfDkiFnflQ5gVcDAwa0FEvABMA5A0DngZeIgs7crnI+K2fH1JpwNzgDOAE4F/lPSetPiLwIVkyRqfkLQiIp7vygcxq+NgYNa+C4CtEfGjIWZqnQ0si4i3gBclbSGb6Q9gS0RsA5C0LNV1MLBS+JmBWfvmAPfnfl+Q5v1ekpvStdXJnsxK4SsDszZIOgL4EHBDKroLuIVsYqZbgNuBK2k8eVPRidigSZ26Obtf/Ux4MHg2vFbq1GbiK2pzN2bdG6leniGvnbY7GJi152LgqYjYBVD7CSDpHuDh9GujSZ0Yovygbs7uVz8THgyeDa+VOrWZ+Ipm1OvGrHsj1csz5LXTdt8mMmvP5eRuEdVm/UsuA55L71cAcyQdKelUYArwONm8HlMknZquMuakumal8JWBWYsk/Q5ZL6BP5or/RtI0sls922vLImKjpAfIHgzvB66NiANpOwvIZgAcByyJiI1d+xBmddoOBu5vbWNVRLwJvKOu7BND1L8VuLWgfBXZzIBWYCyPZylD28HA/a3NzPpHp24Tub+1mVkP61QwKOpvPRdYDyyMiNfI+lCvy9XJ96uu7299btFOutnNrl5RV61OdY9rZzsLp+4/2HWvlXVa3U+r26lid7wqtsmsakYcDLrV3xq6282uXlFXrU51j2tnO/MXrTzYda+VdVrdT6vbqWJ3vCq2yaxqOnFl0JX+1mZmNno6Mc7A/a3NzHrciK4M3N/azKw/jCgYuL+1mVl/cDoKMzNzMDAzMwcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwOzlknaLmmDpKclrU9lEyWtkbQ5/ZyQyiXpTklbJD0r6azcdual+pslzSvr85iBg4FZuz4YEdMiYnr6fRHwaERMAR5Nv0OW4n1Kel1NNt8HkiYCN5JN5HQOcGMtgJiVwcHArDNmA0vT+6XAh3Pl90VmHTA+pXm/CFgTEXvSTIBrgFndbrRZjYOBWesC+I6kJ9NUrACTImInQPp5Qio/icHTup40RLlZKTo1B7LZWHJ+RLwi6QRgjaQfDlG30XSvjcoPXbmL837Xz20Ng+fJbqVObY7uojY3Mx93p+bsblcvz53dTts7MQfydmAvcADYHxHT0/3Q5cAA2QQ3H4+I1yQJ+AJwCfAmMD8inkrbmQd8Jm32sxGxFLMKiohX0s/dkh4iu+e/S9LkiNiZbgPtTtUbTfe6A5hRV762YF8dmfd7oG7eaoDtiy895Pf6ua1h8DzZrdSpzdFdNNd2M/Nxd2rO7nb18tzZ7bS9U7eJ/DDNxgRJR0s6tvYemEk2tesKoNYjaB7w7fR+BTA39So6D3g93UZaDcyUNCEd6zNTmVkpRus20WzePutZSnbG8ylyD9OAdZJqD9NmkB6mAUiqPUy7H7NqmQQ8lF3kchjwtYj4B0lPAA9Iugr4MfCxVH8V2ZXwFrKr4SsAImKPpFvI5gAHuLl2/JuVoRPBoPYwLYD/mS5rD3mYlu6twggfpnXz/mm9ontwnbqn2c52Fk7df/CebCvrtLqfVrdTxfusnWxTRGwD3ltQ/ipwQUF5ANc22NYSYElHGmY2Qp0IBl17mNap+6ftKLoH16l7mu1sZ/6ilQfvybayTqv7aXU7VbzPWsU2mVXNiJ8Z5B+mAYc8TANo4WFaUbmZmXXBiIKBH6aZmfWHkd4m8sM0M7M+MKJg4IdpZmb9wekozMzMwcDMzBwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDAcDMzPDwcDMzHAwMDMzHAzMzAwHAzMzw8HAzMxwMDAzMxwMzFoi6RRJ35W0SdJGSdel8pskvSzp6fS6JLfODZK2SHpB0kW58lmpbIukRWV8HrOaTsyB3BcG6uf1XXxpSS2xitsPLIyIp9Isf09KWpOWfT4ibstXlnQ6MAc4AzgR+EdJ70mLvwhcSDbt6xOSVkTE8135FH3Kf8fta/vKwGdINhZFxM6IeCq93wtsAk4aYpXZwLKIeCsiXiSb5e+c9NoSEdsi4lfAslTXrBQjuTLwGZKNaZIGgPcBjwHnAwskzQXWk/1tvEYWKNblVtvB28Hjpbrycwv2cTVwNcCkSZNYu3ZtW21dOHX/oLL6bXW6zqSjsvdFba7fTrt1OrFOI/v27RvR+mVqp+1tB4M0kf3O9H6vpKbPkIAXJdXOkCCdIQFIqp0hORhYZUk6BngQuD4i3pB0F3ALEOnn7cCVgApWD4qvymNQQcTdwN0A06dPjxkzZrTV3vl1t08Atv/ZjFGts3Dqfm7fcNig5UXbabdOJ9ZpZO3atbT7fZetnbZ35JlBN86Q0n46cpZUZLgziqJI26mzkHbPgGpnXq2s0+p+Wt1OFc+mOt0mSYeTBYKvRsQ3ASJiV275PcDD6dcdwCm51U8GXknvG5Wbdd2Ig0G3zpCgc2dJRYY7oyiKtJ06C2n3DKh25tXKOq3up9XtVPFsqpNtkiTgK8CmiLgjVz45XS0DXAY8l96vAL4m6Q6y26NTgMfJ/h6mSDoVeJnsFup/6kgjzdowomDgMyQbg84HPgFskPR0Kvs0cLmkaWQnMtuBTwJExEZJD5Dd9twPXBsRBwAkLQBWA+OAJRGxsZsfxCyv7WDgMyQbiyLiexRf5a4aYp1bgVsLylcNtZ5ZN43kysBnSGZmfWIkvYl8hmRm1ic8Atm6wiNDzarNuYnMzMzBwMzMHAzMzAwHAzMzw8HAzMxwMDAzMxwMzMwMBwMzM8PBwMzM8AhkMxtjPBq+mIOBWR/wf3A2Ur5NZGZmDgZmZuZgYGZmOBiYmRkVCgaSZkl6QdIWSYvKbo/ZaPMxb1VSid5EksYBXwQuBHYAT0haERHPl9sys9HhY766aj2zFk7dz/z0fiz0zqpEMADOAbZExDYAScuA2WTzJbekvosdjI1/yH7U5/+WHTvmrfv68dhURJTdBiR9FJgVEf85/f4J4NyIWFBX72rg6vTracALXWzmccDPuri/ZrhNzWnUpndFxPHdbgz0zDE/UlU8FlrRy+0fqu2Fx31VrgxUUDYoSkXE3cDdo9+cwSStj4jpZey7EbepOVVsEz1wzI9URb/3pvVy+9tpe1UeIO8ATsn9fjLwSkltMesGH/NWKVUJBk8AUySdKukIYA6wouQ2mY0mH/NWKZW4TRQR+yUtAFYD44AlEbGx5GbVq+KlutvUnMq1qUeO+ZGq3Pfeol5uf8ttr8QDZDMzK1dVbhOZmVmJHAzMzMzBIE/SKZK+K2mTpI2SriuoM0PS65KeTq+/7kK7tkvakPa3vmC5JN2Z0ho8K+msUW7PabnP/7SkNyRdX1dn1L8nSUsk7Zb0XK5soqQ1kjannxMarDsv1dksaV6n2zbWDXfMVs1IjqWyNWj7TZJezv39XTLshiLCr/QCJgNnpffHAv8CnF5XZwbwcJfbtR04bojllwCPkPVdPw94rIttGwf8hGwgS1e/J+ADwFnAc7myvwEWpfeLgM8VrDcR2JZ+TkjvJ5R57PXba7hjtmqvdo+lKrwatP0m4L+2sh1fGeRExM6IeCq93wtsAk4qt1VNmQ3cF5l1wHhJk7u07wuArRHxoy7t76CI+CdgT13xbGBper8U+HDBqhcBayJiT0S8BqwBZo1aQ63yRnAsla5B21vmYNCApAHgfcBjBYv/raRnJD0i6YwuNCeA70h6MqUnqHcS8FLu9x10L4jNAe5vsKzb3xPApIjYCVlwB04oqFPm9zVWDHfM9oJmjqUqW5BuGy9p5haXg0EBSccADwLXR8QbdYufIrsl8l7g74BvdaFJ50fEWcDFwLWSPlC3vKnUBp2WBkt9CPh6weIyvqdmlfJ9jTHDHbM2uu4C/hUwDdgJ3D7cCg4GdSQdThYIvhoR36xfHhFvRMS+9H4VcLik40azTRHxSvq5G3iILONlXlmpDS4GnoqIXfULyviekl21W2Tp5+6COk4FMcqaOGZ7QTPHUiVFxK6IOBARvwHuoYnv38EgR5KArwCbIuKOBnXemeoh6Ryy7/DVUWzT0ZKOrb0HZgLP1VVbAcxNvYrOA16vXd6OsstpcIuo299Tzgqg1jtoHvDtgjqrgZmSJqTL55mpzDqgyWO2FzRzLFVS3TPDy2jm+y/7SXiVXsAfkt0ueBZ4Or0uAa4Brkl1FgAbgWeAdcC/G+U2vTvt65m0379K5fk2iWyilK3ABmB6F76r3yH7z/33cmVd/Z7IAtFO4NdkZ/tXAe8AHgU2p58TU93pwJdz614JbEmvK8o+9vrp1eiYrfKrlWOpaq8Gbf/79H/Bs2RBbfJw23E6CjMz820iMzNzMDAzMxwMzMwMBwMzM8PBwMzMcDAwMzMcDMzMDPj/5xDZ6fAgSWQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8z5mQcPmrFXH"
   },
   "source": [
    "The maximum length of the Spanish sentences is 15 and that of the English phrases is 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxKFJWgCrFXJ"
   },
   "source": [
    "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nesa1bvFrFXK"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6052,
     "status": "ok",
     "timestamp": 1587994183523,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "NYOyPFIyrFXR",
    "outputId": "3539de55-22c2-4d8e-bcee-77d24a625a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9440\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(spa_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 15\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7894,
     "status": "ok",
     "timestamp": 1587994185380,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "tWCyyEldrFXk",
    "outputId": "3bb40740-2998-4a04-f710-280010da5390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Vocabulary Size: 18823\n"
     ]
    }
   ],
   "source": [
    "# prepare Spanish tokenizer\n",
    "spa_tokenizer = tokenization(spa_eng[:, 1])\n",
    "spa_vocab_size = len(spa_tokenizer.word_index) + 1\n",
    "\n",
    "spa_length = 15\n",
    "print('Spanish Vocabulary Size: %d' % spa_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7881,
     "status": "ok",
     "timestamp": 1587994185381,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "LBhHRk6brFXs",
    "outputId": "311206ef-8b18-4f60-c27f-abeb653a9843"
   },
   "outputs": [],
   "source": [
    "##print(spa_tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdZRXOk9rFX3"
   },
   "source": [
    "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dIbwHXSrFYV"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    print(seq)\n",
    "    print(len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVztVGf1rFYc"
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hB3iVhwurFYd"
   },
   "source": [
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BnkO2GRrFYe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(spa_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5KdmUhXrFYm"
   },
   "source": [
    "It's time to encode the sentences. We will encode Spanish sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9899,
     "status": "ok",
     "timestamp": 1587994187435,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "CVL40bhMrFYn",
    "outputId": "baac9862-e4e7-464c-acec-48382be29f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  11  246    4 ...    0    0    0]\n",
      " [  93   15    7 ...    0    0    0]\n",
      " [  40    6    4 ...    0    0    0]\n",
      " ...\n",
      " [  14  292  100 ...    0    0    0]\n",
      " [  52  250 2008 ...    0    0    0]\n",
      " [  18  127 1589 ...    0    0    0]]\n",
      "64000\n",
      "[[   1  223    2 ...    0    0    0]\n",
      " [ 388    5 1608 ...    0    0    0]\n",
      " [  12    7   92 ...    0    0    0]\n",
      " ...\n",
      " [   2  117   10 ...    0    0    0]\n",
      " [  55  480  576 ...    0    0    0]\n",
      " [  13  165  850 ...    0    0    0]]\n",
      "64000\n"
     ]
    }
   ],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(spa_tokenizer, spa_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9888,
     "status": "ok",
     "timestamp": 1587994187435,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "ixhtGaQKrFY7",
    "outputId": "1a5b57e7-e05e-4448-c962-f75e3059224e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 15)\n",
      "(64000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10247,
     "status": "ok",
     "timestamp": 1587994187804,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "kFay-bWIrFZG",
    "outputId": "b481d87d-104c-462c-92bf-1d8aa55f2f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  946 7114 ...    0    0    0]\n",
      " [  25 6256    0 ...    0    0    0]\n",
      " [ 747   33  121 ...    0    0    0]\n",
      " ...\n",
      " [   3    1    2 ...    0    0    0]\n",
      " [ 189  236  451 ...    0    0    0]\n",
      " [7627 3437 2486 ...    0    0    0]]\n",
      "16000\n",
      "[[   3  350   33 ...    0    0    0]\n",
      " [1172   10    0 ...    0    0    0]\n",
      " [  57   62   97 ...    0    0    0]\n",
      " ...\n",
      " [   3   87   29 ...    0    0    0]\n",
      " [ 133    1   59 ...    0    0    0]\n",
      " [  90  856   24 ...    0    0    0]]\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(spa_tokenizer, spa_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10238,
     "status": "ok",
     "timestamp": 1587994187805,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "BmXQ8jDCrFZO",
    "outputId": "538d1d1d-6811-47c4-b261-22c071cdcf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 15)\n",
      "(16000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cB3OPvgYrFZw"
   },
   "source": [
    "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjiL6OtmrFaM"
   },
   "outputs": [],
   "source": [
    "# build NMT model (LSTM)\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units,return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))    \n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoqneCForFfj"
   },
   "source": [
    "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10215,
     "status": "ok",
     "timestamp": 1587994187807,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "aGeKX43yrFfk",
    "outputId": "3398e8ab-415b-4763-f6bd-e18eae95d574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18823\n",
      "9440\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(spa_vocab_size)\n",
    "print(eng_vocab_size)\n",
    "print(spa_length)\n",
    "print(eng_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDu2i0FMrFfo"
   },
   "outputs": [],
   "source": [
    "model = build_model(spa_vocab_size, eng_vocab_size, spa_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIywBS1orFfs"
   },
   "source": [
    "Please note that we have used __'sparse_categorical_crossentropy'__ as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZA0rtHwCrFft"
   },
   "source": [
    "It seems we are all set to start training our model. We will train it for 35 epochs and with a batch size of 320. You may change and play these hyperparameters. We will also be using __ModelCheckpoint()__ to save the best model with lowest validation loss. I personally prefer this method over early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1689585,
     "status": "ok",
     "timestamp": 1587995915485,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "PkhQtVfDrFft",
    "outputId": "63c6bd46-6629-438b-ef82-69ffff2763d8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhelena/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51200 samples, validate on 12800 samples\n",
      "Epoch 1/35\n",
      "51200/51200 [==============================] - 162s 3ms/step - loss: 2.3598 - val_loss: 2.1248\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.12483, saving model to modelLSTM5.h1\n",
      "Epoch 2/35\n",
      "51200/51200 [==============================] - 161s 3ms/step - loss: 1.9986 - val_loss: 1.9802\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.12483 to 1.98017, saving model to modelLSTM5.h1\n",
      "Epoch 3/35\n",
      "51200/51200 [==============================] - 161s 3ms/step - loss: 1.8825 - val_loss: 1.8430\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.98017 to 1.84301, saving model to modelLSTM5.h1\n",
      "Epoch 4/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 1.7550 - val_loss: 1.7180\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.84301 to 1.71797, saving model to modelLSTM5.h1\n",
      "Epoch 5/35\n",
      "51200/51200 [==============================] - 161s 3ms/step - loss: 1.6252 - val_loss: 1.6187\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.71797 to 1.61870, saving model to modelLSTM5.h1\n",
      "Epoch 6/35\n",
      "51200/51200 [==============================] - 161s 3ms/step - loss: 1.5118 - val_loss: 1.5477\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.61870 to 1.54770, saving model to modelLSTM5.h1\n",
      "Epoch 7/35\n",
      "51200/51200 [==============================] - 161s 3ms/step - loss: 1.4132 - val_loss: 1.4439\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.54770 to 1.44387, saving model to modelLSTM5.h1\n",
      "Epoch 8/35\n",
      "51200/51200 [==============================] - 163s 3ms/step - loss: 1.3275 - val_loss: 1.4243\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.44387 to 1.42433, saving model to modelLSTM5.h1\n",
      "Epoch 9/35\n",
      "51200/51200 [==============================] - 162s 3ms/step - loss: 1.2465 - val_loss: 1.3396\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.42433 to 1.33965, saving model to modelLSTM5.h1\n",
      "Epoch 10/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 1.1714 - val_loss: 1.2868\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.33965 to 1.28678, saving model to modelLSTM5.h1\n",
      "Epoch 11/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 1.1004 - val_loss: 1.2454\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.28678 to 1.24540, saving model to modelLSTM5.h1\n",
      "Epoch 12/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 1.0362 - val_loss: 1.2052\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.24540 to 1.20519, saving model to modelLSTM5.h1\n",
      "Epoch 13/35\n",
      "51200/51200 [==============================] - 159s 3ms/step - loss: 0.9770 - val_loss: 1.1840\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.20519 to 1.18402, saving model to modelLSTM5.h1\n",
      "Epoch 14/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.9211 - val_loss: 1.1584\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.18402 to 1.15843, saving model to modelLSTM5.h1\n",
      "Epoch 15/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.8704 - val_loss: 1.1396\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.15843 to 1.13962, saving model to modelLSTM5.h1\n",
      "Epoch 16/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.8198 - val_loss: 1.1119\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.13962 to 1.11187, saving model to modelLSTM5.h1\n",
      "Epoch 17/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.7735 - val_loss: 1.1078\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.11187 to 1.10785, saving model to modelLSTM5.h1\n",
      "Epoch 18/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.7305 - val_loss: 1.0902\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.10785 to 1.09023, saving model to modelLSTM5.h1\n",
      "Epoch 19/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.6888 - val_loss: 1.0807\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.09023 to 1.08071, saving model to modelLSTM5.h1\n",
      "Epoch 20/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.6509 - val_loss: 1.0799\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.08071 to 1.07993, saving model to modelLSTM5.h1\n",
      "Epoch 21/35\n",
      "51200/51200 [==============================] - 159s 3ms/step - loss: 0.6141 - val_loss: 1.0712\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.07993 to 1.07117, saving model to modelLSTM5.h1\n",
      "Epoch 22/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.5806 - val_loss: 1.0840\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.07117\n",
      "Epoch 23/35\n",
      "51200/51200 [==============================] - 159s 3ms/step - loss: 0.5484 - val_loss: 1.0839\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.07117\n",
      "Epoch 24/35\n",
      "51200/51200 [==============================] - 159s 3ms/step - loss: 0.5175 - val_loss: 1.0740\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.07117\n",
      "Epoch 25/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.4889 - val_loss: 1.0841\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.07117\n",
      "Epoch 26/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.4625 - val_loss: 1.0738\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.07117\n",
      "Epoch 27/35\n",
      "51200/51200 [==============================] - 159s 3ms/step - loss: 0.4377 - val_loss: 1.0794\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.07117\n",
      "Epoch 28/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.4136 - val_loss: 1.0896\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.07117\n",
      "Epoch 29/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.3910 - val_loss: 1.1156\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.07117\n",
      "Epoch 30/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.3700 - val_loss: 1.1041\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.07117\n",
      "Epoch 31/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.3502 - val_loss: 1.1038\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.07117\n",
      "Epoch 32/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.3327 - val_loss: 1.1108\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.07117\n",
      "Epoch 33/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.3168 - val_loss: 1.1235\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.07117\n",
      "Epoch 34/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.2998 - val_loss: 1.1261\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.07117\n",
      "Epoch 35/35\n",
      "51200/51200 [==============================] - 160s 3ms/step - loss: 0.2845 - val_loss: 1.1423\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.07117\n"
     ]
    }
   ],
   "source": [
    "filename = 'modelLSTM5.h1'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=35, batch_size=320, #512 \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_m-YgnEDrFf0"
   },
   "source": [
    "Let's compare the training loss and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1587995949133,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "tVCZmNRArFf2",
    "outputId": "f14d2abe-8256-4092-8dd9-c7d68d89af4f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUpkQyCfrFgH"
   },
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2ZRBLYWrFgj"
   },
   "source": [
    "Let's load the saved model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2072,
     "status": "error",
     "timestamp": 1588001195764,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "tzzkClmKrFgw",
    "outputId": "2047a843-1741-4d7e-d082-75ea6f19f8c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhelena/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model = load_model('modelLSTM5.h1')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HyNCtu4mrFiJ"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJ8E4c_crFjQ"
   },
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbdmiipLrFkn"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'Spanish':  test[:,1], 'actual traduction' : test[:,0], 'predicted' : preds_text})\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 359309,
     "status": "ok",
     "timestamp": 1587996315020,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "PfXt-Su_rFmv",
    "outputId": "e854d2d6-264f-49c2-9c27-f8cbf3659ed5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spanish</th>\n",
       "      <th>actual traduction</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tom sentía temblar sus rodillas</td>\n",
       "      <td>tom felt his knees tremble</td>\n",
       "      <td>tom lost his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eso valdrá</td>\n",
       "      <td>thatll do</td>\n",
       "      <td>thatll do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volveré más tarde</td>\n",
       "      <td>ill come back later</td>\n",
       "      <td>ill will back later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estoy reventado</td>\n",
       "      <td>i am exhausted</td>\n",
       "      <td>im exhausted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no lo hagáis</td>\n",
       "      <td>dont do it</td>\n",
       "      <td>dont ask it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>me duele la muela del juicio superior derecha</td>\n",
       "      <td>my upper right wisdom tooth hurts</td>\n",
       "      <td>my  only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ya lo has olvidado</td>\n",
       "      <td>youve already forgotten</td>\n",
       "      <td>youve already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>¿por qué llevas un suéter</td>\n",
       "      <td>why are you wearing a sweater</td>\n",
       "      <td>why are you wearing a coat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no me subestimes</td>\n",
       "      <td>dont underestimate me</td>\n",
       "      <td>dont ask me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eso fue idea mía</td>\n",
       "      <td>it was my idea</td>\n",
       "      <td>that was my idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no estaba celoso</td>\n",
       "      <td>i was not jealous</td>\n",
       "      <td>i wasnt jealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ella se puso enferma pero se recuperó rápido</td>\n",
       "      <td>she fell ill but got well soon</td>\n",
       "      <td>she was him as i been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>es por tu propia seguridad</td>\n",
       "      <td>its for your own safety</td>\n",
       "      <td>its about your  fault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>¿sabes cómo anudar una corbata</td>\n",
       "      <td>do you know how to tie a tie</td>\n",
       "      <td>do you know how to tie a tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>entra en la habitación</td>\n",
       "      <td>come into the room</td>\n",
       "      <td>come on the room</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Spanish  \\\n",
       "0                 tom sentía temblar sus rodillas   \n",
       "1                                      eso valdrá   \n",
       "2                               volveré más tarde   \n",
       "3                                 estoy reventado   \n",
       "4                                    no lo hagáis   \n",
       "5   me duele la muela del juicio superior derecha   \n",
       "6                              ya lo has olvidado   \n",
       "7                       ¿por qué llevas un suéter   \n",
       "8                                no me subestimes   \n",
       "9                                eso fue idea mía   \n",
       "10                               no estaba celoso   \n",
       "11   ella se puso enferma pero se recuperó rápido   \n",
       "12                     es por tu propia seguridad   \n",
       "13                 ¿sabes cómo anudar una corbata   \n",
       "14                         entra en la habitación   \n",
       "\n",
       "                    actual traduction                            predicted  \n",
       "0          tom felt his knees tremble             tom lost his              \n",
       "1                           thatll do               thatll do               \n",
       "2                 ill come back later       ill will back later             \n",
       "3                      i am exhausted            im exhausted               \n",
       "4                          dont do it              dont ask it              \n",
       "5   my upper right wisdom tooth hurts                 my  only              \n",
       "6             youve already forgotten           youve already               \n",
       "7       why are you wearing a sweater  why are you wearing a coat           \n",
       "8               dont underestimate me              dont ask me              \n",
       "9                      it was my idea          that was my idea             \n",
       "10                  i was not jealous          i wasnt jealous              \n",
       "11     she fell ill but got well soon       she was him as i been           \n",
       "12            its for your own safety      its about your  fault            \n",
       "13       do you know how to tie a tie  do you know how to tie a tie         \n",
       "14                 come into the room          come on the room             "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 359301,
     "status": "ok",
     "timestamp": 1587996315020,
     "user": {
      "displayName": "Marina Martínez Steegmann",
      "photoUrl": "",
      "userId": "13872820662452395977"
     },
     "user_tz": -120
    },
    "id": "YrCFJ63MrFsN",
    "outputId": "9d8382fd-cd6a-4b0f-9a50-868f46cfe110"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spanish</th>\n",
       "      <th>actual traduction</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9806</th>\n",
       "      <td>es solo que no quiero decepcionarte</td>\n",
       "      <td>i just dont want to let you down</td>\n",
       "      <td>it just  want to  waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7729</th>\n",
       "      <td>tú me diviertes</td>\n",
       "      <td>you amuse me</td>\n",
       "      <td>you worried me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>no quise lastimarte</td>\n",
       "      <td>i didnt want to hurt you</td>\n",
       "      <td>i didnt want to hurt you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>¿puedo preguntarle cuál prefiere</td>\n",
       "      <td>may i ask which you prefer</td>\n",
       "      <td>may i ask how to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>¿estás enfadado conmigo</td>\n",
       "      <td>are you angry with me</td>\n",
       "      <td>are you angry with me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>¿quieres decir algo</td>\n",
       "      <td>do you want to say something</td>\n",
       "      <td>do you want something say something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>¿qué ocurre cuando mueres</td>\n",
       "      <td>what happens when you die</td>\n",
       "      <td>what time he  come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>tom espera verte en octubre</td>\n",
       "      <td>tom hopes to see you in october</td>\n",
       "      <td>tom will to stay  tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>cualquier lugar con cama estará bien</td>\n",
       "      <td>anywhere with a bed will do</td>\n",
       "      <td>after us to   gets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>me perdí en el bosque</td>\n",
       "      <td>i lost my way in the forest</td>\n",
       "      <td>i got lost in the woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>los niños a menudo hacen estupideces</td>\n",
       "      <td>children often do stupid things</td>\n",
       "      <td>children  need send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>quiero que te sientes aquí</td>\n",
       "      <td>i want you to sit here</td>\n",
       "      <td>i want you to stay here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14784</th>\n",
       "      <td>tom es la persona a preguntar</td>\n",
       "      <td>tom is the person to ask</td>\n",
       "      <td>tom is the only i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>todos los manzanos fueron talados</td>\n",
       "      <td>all the apple trees were cut down</td>\n",
       "      <td>all the were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>el tío está como una cabra</td>\n",
       "      <td>that guy is off his rocker</td>\n",
       "      <td>the guy is an nuts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Spanish  \\\n",
       "9806    es solo que no quiero decepcionarte   \n",
       "7729                        tú me diviertes   \n",
       "10138                   no quise lastimarte   \n",
       "1173       ¿puedo preguntarle cuál prefiere   \n",
       "5076                ¿estás enfadado conmigo   \n",
       "800                     ¿quieres decir algo   \n",
       "2869              ¿qué ocurre cuando mueres   \n",
       "5962            tom espera verte en octubre   \n",
       "1908   cualquier lugar con cama estará bien   \n",
       "982                   me perdí en el bosque   \n",
       "14607  los niños a menudo hacen estupideces   \n",
       "13344            quiero que te sientes aquí   \n",
       "14784         tom es la persona a preguntar   \n",
       "4911      todos los manzanos fueron talados   \n",
       "767              el tío está como una cabra   \n",
       "\n",
       "                       actual traduction  \\\n",
       "9806    i just dont want to let you down   \n",
       "7729                        you amuse me   \n",
       "10138           i didnt want to hurt you   \n",
       "1173          may i ask which you prefer   \n",
       "5076               are you angry with me   \n",
       "800         do you want to say something   \n",
       "2869           what happens when you die   \n",
       "5962     tom hopes to see you in october   \n",
       "1908         anywhere with a bed will do   \n",
       "982          i lost my way in the forest   \n",
       "14607    children often do stupid things   \n",
       "13344             i want you to sit here   \n",
       "14784           tom is the person to ask   \n",
       "4911   all the apple trees were cut down   \n",
       "767           that guy is off his rocker   \n",
       "\n",
       "                                          predicted  \n",
       "9806                it just  want to  waste          \n",
       "7729                     you worried me              \n",
       "10138             i didnt want to hurt you           \n",
       "1173                     may i ask how to            \n",
       "5076                are you angry with me            \n",
       "800    do you want something say something           \n",
       "2869                   what time he  come            \n",
       "5962                  tom will to stay  tv           \n",
       "1908                    after us to   gets           \n",
       "982                i got lost in the woods           \n",
       "14607                children  need send             \n",
       "13344              i want you to stay here           \n",
       "14784                   tom is the only i            \n",
       "4911                       all the were              \n",
       "767                    the guy is an nuts            "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "B0wbcBMDrFWL"
   ],
   "machine_shape": "hm",
   "name": "80000_lines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Anaconda3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
